{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "from math import sqrt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"Mean of empty slice\")\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, file_path):\n",
    "        self.file_path = file_path\n",
    "\n",
    "    def load_data(self):\n",
    "        ratings_df = pd.read_csv(self.file_path)\n",
    "        return ratings_df\n",
    "\n",
    "class DataPreprocessor:\n",
    "    def __init__(self, ratings_df, movies_df, n):\n",
    "        self.ratings_df = ratings_df\n",
    "        self.movies_df = movies_df\n",
    "        self.n = n\n",
    "\n",
    "    def preprocess(self):\n",
    "        ratings_df_sample = self.ratings_df[:self.n]\n",
    "        self.n_users = len(ratings_df_sample['userId'].unique())\n",
    "        self.n_movies = len(ratings_df_sample['movieId'].unique())\n",
    "        movie_ids = ratings_df_sample['movieId'].unique()\n",
    "        self.movies_df = self.movies_df[self.movies_df['movieId'].isin(movie_ids)]\n",
    "\n",
    "\n",
    "\n",
    "        def scale_movie_id(movie_id):\n",
    "            scaled = np.where(movie_ids == movie_id)[0][0] + 1\n",
    "            return scaled\n",
    "\n",
    "        def clean_title(x):\n",
    "            x = x.split(\" (\")[0]  \n",
    "            x = re.sub(\"[^a-zA-Z0-9 ]\", \"\", x)  \n",
    "            x = x.strip()\n",
    "            return x\n",
    "\n",
    "        ratings_df_sample.loc[:, 'movieId'] = ratings_df_sample['movieId'].apply(scale_movie_id)\n",
    "        movie_ids =  self.movies_df['movieId'].unique()\n",
    "        self.movies_df.loc[:, 'movieId'] = self.movies_df['movieId'].apply(scale_movie_id)\n",
    "        self.movies_df.loc[:, 'title'] = self.movies_df['title'].apply(clean_title)\n",
    "        vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "        tfidf_matrix = vectorizer.fit_transform(self.movies_df['title'])\n",
    "        train_data, test_data = train_test_split(ratings_df_sample, test_size=0.2)\n",
    "        return train_data, test_data, self.movies_df, tfidf_matrix, vectorizer, self.n_users, self.n_movies\n",
    "\n",
    "class RecommenderModel:\n",
    "    def __init__(self, n_users, n_movies, movies_df, tfidf_matrix, vectorizer):\n",
    "        self.n_users = n_users\n",
    "        self.n_movies = n_movies\n",
    "        self.movies_df = movies_df\n",
    "        self.tfidf_matrix = tfidf_matrix\n",
    "        self.vectorizer = vectorizer\n",
    "\n",
    "    def train(self, train_data):\n",
    "        self.train_data_matrix = np.zeros((self.n_users, self.n_movies))\n",
    "        for line in train_data.itertuples():\n",
    "            self.train_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n",
    "\n",
    "        self.user_similarity = pairwise_distances(self.train_data_matrix, metric='cosine')\n",
    "        self.item_similarity = pairwise_distances(self.train_data_matrix.T, metric='cosine')\n",
    "\n",
    "    def search(self, title):\n",
    "        title = title.strip() \n",
    "        query_vec = self.vectorizer.transform([title])\n",
    "        similarity = cosine_similarity(query_vec, self.tfidf_matrix).flatten()\n",
    "        index = similarity.argsort()[-1] \n",
    "        return self.movies_df.iloc[index]['movieId']\n",
    "    \n",
    "    def recommend_movies(self, movie_ratings, n_recommendations=5):\n",
    "        user_data_matrix = np.zeros((1, self.n_movies))\n",
    "        for movie_name, rating in movie_ratings.items():\n",
    "            movie_index_test = self.search(movie_name)\n",
    "            user_data_matrix[0, movie_index_test] = rating\n",
    "\n",
    "        user_pred = self.k_fract_mean_predict(7)  \n",
    "        user_recommendations = user_pred[0].argsort()[::-1][:n_recommendations]\n",
    "\n",
    "        recommended_movies = []\n",
    "        for movie_id in user_recommendations:\n",
    "            recommended_movies.append(movie_id + 1) \n",
    "\n",
    "        return list(self.movies_df[self.movies_df['movieId'].isin(recommended_movies)]['title'])\n",
    "\n",
    "    def predict(self, top, type='user'):\n",
    "        if type == 'user':\n",
    "            return self.naive_predict(top)\n",
    "        elif type == 'item':\n",
    "            return self.naive_predict_item(top)\n",
    "        elif type == 'user_k_fract':\n",
    "            return self.k_fract_predict(top)\n",
    "        elif type == 'item_k_fract':\n",
    "            return self.k_fract_predict_item(top)\n",
    "        elif type == 'user_k_fract_mean':\n",
    "            return self.k_fract_mean_predict(top)\n",
    "        elif type == 'item_k_fract_mean':\n",
    "            return self.k_fract_mean_predict_item(top)\n",
    "\n",
    "    def naive_predict(self, top):\n",
    "        top_similar_ratings = np.zeros((self.n_users, top, self.n_movies))\n",
    "        for i in range(self.n_users):\n",
    "            top_sim_users = self.user_similarity[i].argsort()[1:top + 1]\n",
    "            top_similar_ratings[i] = self.train_data_matrix[top_sim_users]\n",
    "\n",
    "        pred = np.zeros((self.n_users, self.n_movies))\n",
    "        for i in range(self.n_users):\n",
    "            pred[i] = top_similar_ratings[i].sum(axis=0) / top\n",
    "        return pred\n",
    "\n",
    "    def naive_predict_item(self, top):\n",
    "        top_similar_ratings = np.zeros((self.n_movies, top, self.n_users))\n",
    "        for i in range(self.n_movies):\n",
    "            top_sim_movies = self.item_similarity[i].argsort()[1:top + 1]\n",
    "            top_similar_ratings[i] = self.train_data_matrix.T[top_sim_movies]\n",
    "\n",
    "        pred = np.zeros((self.n_movies, self.n_users))\n",
    "        for i in range(self.n_movies):\n",
    "            pred[i] = top_similar_ratings[i].sum(axis=0) / top\n",
    "        return pred.T\n",
    "\n",
    "    def k_fract_predict(self, top):\n",
    "        top_similar = np.zeros((self.n_users, top))\n",
    "        for i in range(self.n_users):\n",
    "            user_sim = self.user_similarity[i]\n",
    "            top_sim_users = user_sim.argsort()[1:top + 1]\n",
    "            for j in range(top):\n",
    "                top_similar[i, j] = top_sim_users[j]\n",
    "\n",
    "        abs_sim = np.abs(self.user_similarity)\n",
    "        pred = np.zeros((self.n_users, self.n_movies))\n",
    "        for i in range(self.n_users):\n",
    "            indexes = top_similar[i].astype(int)\n",
    "            numerator = self.user_similarity[i][indexes]\n",
    "            product = numerator.dot(self.train_data_matrix[indexes])\n",
    "            denominator = abs_sim[i][top_similar[i].astype(int)].sum()\n",
    "            pred[i] = product / denominator\n",
    "        return pred\n",
    "\n",
    "    def k_fract_predict_item(self, top):\n",
    "        top_similar = np.zeros((self.n_movies, top))\n",
    "        for i in range(self.n_movies):\n",
    "            movies_sim = self.item_similarity[i]\n",
    "            top_sim_movies = movies_sim.argsort()[1:top + 1]\n",
    "            for j in range(top):\n",
    "                top_similar[i, j] = top_sim_movies.T[j]\n",
    "\n",
    "        abs_sim = np.abs(self.item_similarity)\n",
    "        pred = np.zeros((self.n_movies, self.n_users))\n",
    "        for i in range(self.n_movies):\n",
    "            indexes = top_similar[i].astype(int)\n",
    "            numerator = self.item_similarity[i][indexes]\n",
    "            product = numerator.dot(self.train_data_matrix.T[indexes])\n",
    "            denominator = abs_sim[i][indexes].sum()\n",
    "            denominator = denominator if denominator != 0 else 1\n",
    "            pred[i] = product / denominator\n",
    "        return pred.T\n",
    "\n",
    "    def k_fract_mean_predict(self, top):\n",
    "        top_similar = np.zeros((self.n_users, top))\n",
    "        for i in range(self.n_users):\n",
    "            user_sim = self.user_similarity[i]\n",
    "            top_sim_users = user_sim.argsort()[1:top + 1]\n",
    "            for j in range(top):\n",
    "                top_similar[i, j] = top_sim_users[j]\n",
    "\n",
    "        abs_sim = np.abs(self.user_similarity)\n",
    "        pred = np.zeros((self.n_users, self.n_movies))\n",
    "        for i in range(self.n_users):\n",
    "            indexes = top_similar[i].astype(int)\n",
    "            numerator = self.user_similarity[i][indexes]\n",
    "            mean_rating = np.nanmean([x for x in self.train_data_matrix[i] if x > 0])\n",
    "            if np.isnan(mean_rating):\n",
    "                mean_rating = 0\n",
    "            diff_ratings = self.train_data_matrix[indexes] - np.nanmean(self.train_data_matrix[indexes], axis=0)\n",
    "            numerator = numerator.dot(diff_ratings)\n",
    "            denominator = abs_sim[i][top_similar[i].astype(int)].sum()\n",
    "            pred[i] = mean_rating + numerator / denominator if denominator != 0 else mean_rating\n",
    "        return pred\n",
    "\n",
    "    def k_fract_mean_predict_item(self, top):\n",
    "        top_similar = np.zeros((self.n_movies, top))\n",
    "        for i in range(self.n_movies):\n",
    "            movie_sim = self.item_similarity[i]\n",
    "            top_sim_movies = movie_sim.argsort()[1:top + 1]\n",
    "            for j in range(top):\n",
    "                top_similar[i, j] = top_sim_movies[j]\n",
    "\n",
    "        abs_sim = np.abs(self.item_similarity)\n",
    "        pred = np.zeros((self.n_movies, self.n_users))\n",
    "        for i in range(self.n_movies):\n",
    "            indexes = top_similar[i].astype(int)\n",
    "            numerator = self.item_similarity[i][indexes]\n",
    "            diff_ratings = self.train_data_matrix.T[indexes] - np.nanmean(self.train_data_matrix.T[indexes], axis=0)\n",
    "            numerator = numerator.dot(diff_ratings)\n",
    "            denominator = abs_sim[i][top_similar[i].astype(int)].sum()\n",
    "            denominator = denominator if denominator != 0 else 1\n",
    "            mean_rating = np.nanmean([x for x in self.train_data_matrix.T[i] if x > 0])\n",
    "            mean_rating = 0 if np.isnan(mean_rating) else mean_rating\n",
    "            pred[i] = mean_rating + numerator / denominator\n",
    "        return pred.T\n",
    "\n",
    "def rmse(prediction, ground_truth):\n",
    "    prediction = np.nan_to_num(prediction)[ground_truth.nonzero()].flatten()\n",
    "    ground_truth = np.nan_to_num(ground_truth)[ground_truth.nonzero()].flatten()\n",
    "    mse = mean_squared_error(prediction, ground_truth)\n",
    "    return sqrt(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique users count: 330975\n",
      "Unique movies count: 83239\n",
      "DataFrame shape: (33832162, 4)\n",
      "Train shape: (80000, 4)\n",
      "Test shape: (20000, 4)\n",
      "User-based CF RMSE: 2.933015052112479\n",
      "Item-based CF RMSE: 3.060378836426788\n",
      "User-based CF RMSE (k_fract): 2.9338878493556977\n",
      "Item-based CF RMSE (k_fract): 3.0628380911081603\n",
      "User-based CF RMSE (k_fract_mean): 0.9474072447156595\n",
      "Item-based CF RMSE (k_fract_mean): 1.265143026359543\n"
     ]
    }
   ],
   "source": [
    "data_loader_ratings = DataLoader('data/ratings.csv')\n",
    "ratings_df = data_loader_ratings.load_data()\n",
    "\n",
    "data_loader_movies = DataLoader('data/movies.csv')\n",
    "movies_df = data_loader_movies.load_data()\n",
    "\n",
    "print(f'Unique users count: {len(ratings_df[\"userId\"].unique())}')\n",
    "print(f'Unique movies count: {len(ratings_df[\"movieId\"].unique())}')\n",
    "print(f'DataFrame shape: {ratings_df.shape}')\n",
    "\n",
    "# Preprocess data\n",
    "n = 100000\n",
    "data_preprocessor = DataPreprocessor(ratings_df, movies_df, n)\n",
    "train_data, test_data, movies_df, tdif_matrix, vectorizer, n_users, n_movies = data_preprocessor.preprocess()\n",
    "print(f'Train shape: {train_data.shape}')\n",
    "print(f'Test shape: {test_data.shape}')\n",
    "\n",
    "# Train model\n",
    "recommender_model = RecommenderModel(n_users, n_movies, movies_df, tdif_matrix, vectorizer)\n",
    "recommender_model.train(train_data)\n",
    "\n",
    "# Create test data matrix\n",
    "test_data_matrix = np.zeros((n_users, n_movies))\n",
    "for line in test_data.itertuples():\n",
    "    test_data_matrix[line[1] - 1, line[2] - 1] = line[3]\n",
    "\n",
    "# Make predictions and evaluate\n",
    "naive_pred = recommender_model.predict(7, type='user')\n",
    "print('User-based CF RMSE:', rmse(naive_pred, test_data_matrix))\n",
    "\n",
    "naive_pred_item = recommender_model.predict(7, type='item')\n",
    "print('Item-based CF RMSE:', rmse(naive_pred_item, test_data_matrix))\n",
    "\n",
    "k_predict = recommender_model.predict(7, type='user_k_fract')\n",
    "print('User-based CF RMSE (k_fract):', rmse(k_predict, test_data_matrix))\n",
    "\n",
    "k_predict_item = recommender_model.predict(7, type='item_k_fract')\n",
    "print('Item-based CF RMSE (k_fract):', rmse(k_predict_item, test_data_matrix))\n",
    "\n",
    "k_predict_mean = recommender_model.predict(7, type='user_k_fract_mean')\n",
    "print('User-based CF RMSE (k_fract_mean):', rmse(k_predict_mean, test_data_matrix))\n",
    "\n",
    "k_predict_item_mean = recommender_model.predict(7, type='item_k_fract_mean')\n",
    "print('Item-based CF RMSE (k_fract_mean):', rmse(k_predict_item_mean, test_data_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations:\n",
      "Now and Then\n",
      "Umbrellas of Cherbourg The\n",
      "National Lampoons Senior Trip\n",
      "Angus\n",
      "Haunted World of Edward D Wood Jr The\n"
     ]
    }
   ],
   "source": [
    "def recommend_movies_from_terminal():\n",
    "    movies_input = input(\"Enter movies separated by commas: \")\n",
    "    ratings_input = input(\"Enter ratings separated by commas: \")\n",
    "\n",
    "    movies_list = movies_input.split(',')\n",
    "    ratings_list = [float(rating.strip()) for rating in ratings_input.split(',')]\n",
    "\n",
    "    movie_ratings = dict(zip(movies_list, ratings_list))\n",
    "    recommended_movie_ids = recommender_model.recommend_movies(movie_ratings, n_recommendations=5)\n",
    "    print(\"Recommendations:\")\n",
    "    for movie_name in recommended_movie_ids:\n",
    "        print(movie_name)\n",
    "\n",
    "recommend_movies_from_terminal()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
